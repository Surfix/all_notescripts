{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook converts snodas .dat files to tiff file\n",
    "\n",
    "- List all files in the folder with .dat extension\n",
    "- for each of the file:\n",
    "    - copy copy.hdr with the filename.\n",
    "    - gdaltrantranslate to tiff with appropriate variable name\n",
    "    - read with xarrya and rescale if necessary\n",
    "    - save with the appropriate name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "from os import path\n",
    "import shutil\n",
    "import rioxarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now copying us_ssmv01025SlL01T0024TTNATS2021032205DP001.hdr\n",
      "Now copying us_ssmv11034tS__T0001TTNATS2021032205HP001.hdr\n",
      "Now copying us_ssmv01025SlL00T0024TTNATS2021032205DP001.hdr\n",
      "Now copying us_ssmv11036tS__T0001TTNATS2021032205HP001.hdr\n",
      "Now copying us_ssmv11039lL00T0024TTNATS2021032205DP000.hdr\n",
      "Now copying us_ssmv11044bS__T0024TTNATS2021032205DP000.hdr\n",
      "Now copying us_ssmv11038wS__A0024TTNATS2021032205DP001.hdr\n",
      "Now copying us_ssmv11050lL00T0024TTNATS2021032205DP000.hdr\n"
     ]
    }
   ],
   "source": [
    "# #define path to the folder\n",
    "# dir_path = '/home/naheemadebisi/PhD/snow-analytics/lidar/validating_SNODAS/data_results/all_snodas/SNODAS_20210322'\n",
    "# #cahnge the working directory\n",
    "# os.chdir(dir_path)\n",
    "\n",
    "# for file in os.listdir(dir_path):\n",
    "#     if file.endswith('.dat'):\n",
    "#         #print(file)\n",
    "#         file_name = path.splitext(file)[0] + '.hdr'\n",
    "#         print(f\"Now copying {file_name}\")\n",
    "\n",
    "#         #shutil.copyfile('copy.hdr', file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| chracters | variable |\n",
    "| --- | --- |\n",
    "| us_ssmv01025SlL01 | snow_precip |\n",
    "| us_ssmv11034tS | SWE |\n",
    "| us_ssmv01025SlL00 | liquid_precip |\n",
    "| us_ssmv11036tS | snow_depth |\n",
    "| us_ssmv11039lL00 | blow_snow_sublim |\n",
    "| us_ssmv11044bS | snow_melt_base |\n",
    "| us_ssmv11038wS | sp_avg_temp |\n",
    "| us_ssmv11050 | sp_sublim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now converting us_ssmv01025SlL01T0024TTNATS2019122005DP001.dat\n",
      "Input file size is 6935, 3351\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Now converting us_ssmv11036tS__T0001TTNATS2019122005HP001.dat\n",
      "Input file size is 6935, 3351\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Now converting us_ssmv11039lL00T0024TTNATS2019122005DP000.dat\n",
      "Input file size is 6935, 3351\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Now converting us_ssmv11050lL00T0024TTNATS2019122005DP000.dat\n",
      "Input file size is 6935, 3351\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Now converting us_ssmv11038wS__A0024TTNATS2019122005DP001.dat\n",
      "Input file size is 6935, 3351\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Now converting us_ssmv11034tS__T0001TTNATS2019122005HP001.dat\n",
      "Input file size is 6935, 3351\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Now converting us_ssmv11044bS__T0024TTNATS2019122005DP000.dat\n",
      "Input file size is 6935, 3351\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Now converting us_ssmv01025SlL00T0024TTNATS2019122005DP001.dat\n",
      "Input file size is 6935, 3351\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    }
   ],
   "source": [
    "#define path to the folder\n",
    "dir_path = '/home/naheemadebisi/PhD/snow-analytics/lidar/validating_SNODAS/data_results/all_snodas/SNODAS_20191220'\n",
    "#cahnge the working directory\n",
    "os.chdir(dir_path)\n",
    "\n",
    "for file in os.listdir(dir_path):\n",
    "    if file.endswith('.dat'):\n",
    "        #copy the copy.hdr to the file name\n",
    "        shutil.copyfile('copy.hdr', path.splitext(file)[0] + '.hdr')\n",
    "        \n",
    "        in_file = file\n",
    "        #snow_precip\n",
    "        if 'us_ssmv01025SlL01' in in_file:\n",
    "            tiff_name = 'us_ssmv01025SlL01_' + 'snow_precip_' + path.split(dir_path)[-1] + '.tif'\n",
    "            print(f\"Now converting {in_file}\")\n",
    "            os.system(f\"gdal_translate -of GTiff -a_srs '+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs' -a_nodata -9999 -a_ullr -124.73333333333333 52.87500000000000 -66.94166666666667 24.95000000000000 {in_file} {tiff_name}\")\n",
    "            \n",
    "            #define the name to save the final file after scaling\n",
    "            out_file = 'us_ssmv01025SlL01_' + 'snow_precip_' + path.split(dir_path)[-1] + '_kgm2.tif'\n",
    "            #read as array and rescale\n",
    "            arr = xr.open_rasterio(tiff_name, masked = True)\n",
    "            arr = arr/10\n",
    "            arr.rio.to_raster(out_file)\n",
    "            \n",
    "            #let's remove the redundant file\n",
    "            if os.path.exists(tiff_name):\n",
    "                os.remove(tiff_name)\n",
    "\n",
    "\n",
    "        #SWE\n",
    "        elif 'us_ssmv11034tS' in in_file:\n",
    "            tiff_name = 'us_ssmv11034tS_' + 'SWE_' + path.split(dir_path)[-1] + '.tif'\n",
    "            print(f\"Now converting {in_file}\")\n",
    "            os.system(f\"gdal_translate -of GTiff -a_srs '+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs' -a_nodata -9999 -a_ullr -124.73333333333333 52.87500000000000 -66.94166666666667 24.95000000000000 {in_file} {tiff_name}\")\n",
    "            \n",
    "            #define the name to save the final file after scaling\n",
    "            out_file = 'us_ssmv11034tS_' + 'SWE_' + path.split(dir_path)[-1] + '_m.tif'\n",
    "            #read as array and rescale\n",
    "            arr = xr.open_rasterio(tiff_name, masked = True)\n",
    "            arr = arr/1000\n",
    "            arr.rio.to_raster(out_file)\n",
    "            \n",
    "            #let's remove the redundant file\n",
    "            if os.path.exists(tiff_name):\n",
    "                os.remove(tiff_name)\n",
    "        \n",
    "        #liquid_precip\n",
    "        if 'us_ssmv01025SlL00' in in_file:\n",
    "            tiff_name = 'us_ssmv01025SlL00_' + 'liquid_precip_' + path.split(dir_path)[-1] + '.tif'\n",
    "            print(f\"Now converting {in_file}\")\n",
    "            os.system(f\"gdal_translate -of GTiff -a_srs '+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs' -a_nodata -9999 -a_ullr -124.73333333333333 52.87500000000000 -66.94166666666667 24.95000000000000 {in_file} {tiff_name}\")\n",
    "            \n",
    "            #define the name to save the final file after scaling\n",
    "            out_file = 'us_ssmv01025SlL00_' + 'liquid_precip_' + path.split(dir_path)[-1] + '_kgm2.tif'\n",
    "            #read as array and rescale\n",
    "            arr = xr.open_rasterio(tiff_name, masked = True)\n",
    "            arr = arr/10\n",
    "            arr.rio.to_raster(out_file)\n",
    "            \n",
    "            #let's remove the redundant file\n",
    "            if os.path.exists(tiff_name):\n",
    "                os.remove(tiff_name)\n",
    "\n",
    "        #snowdepth\n",
    "        elif 'us_ssmv11036tS' in in_file:\n",
    "            tiff_name = 'us_ssmv11036tS_' + 'snow_depth_' + path.split(dir_path)[-1] + '.tif'\n",
    "            print(f\"Now converting {in_file}\")\n",
    "            os.system(f\"gdal_translate -of GTiff -a_srs '+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs' -a_nodata -9999 -a_ullr -124.73333333333333 52.87500000000000 -66.94166666666667 24.95000000000000 {in_file} {tiff_name}\")\n",
    "            \n",
    "            #define the name to save the final file after scaling\n",
    "            out_file = 'us_ssmv11036tS_' + 'snow_depth_' + path.split(dir_path)[-1] + '_m.tif'\n",
    "            #read as array and rescale\n",
    "            arr = xr.open_rasterio(tiff_name, masked = True)\n",
    "            arr = arr/1000\n",
    "            arr.rio.to_raster(out_file)\n",
    "            \n",
    "            #let's remove the redundant file\n",
    "            if os.path.exists(tiff_name):\n",
    "                os.remove(tiff_name)\n",
    "\n",
    "        #blow_snow_sublim\n",
    "        elif 'us_ssmv11039lL00' in in_file:\n",
    "            tiff_name = 'us_ssmv11039lL00_' + 'blow_snow_sublim_' + path.split(dir_path)[-1] + '.tif'\n",
    "            print(f\"Now converting {in_file}\")\n",
    "            os.system(f\"gdal_translate -of GTiff -a_srs '+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs' -a_nodata -9999 -a_ullr -124.73333333333333 52.87500000000000 -66.94166666666667 24.95000000000000 {in_file} {tiff_name}\")\n",
    "            \n",
    "            #define the name to save the final file after scaling\n",
    "            out_file = 'us_ssmv11039lL00_' + 'blow_snow_sublim_' + path.split(dir_path)[-1] + '_m.tif'\n",
    "            #read as array and rescale\n",
    "            arr = xr.open_rasterio(tiff_name, masked = True)\n",
    "            arr = arr/100000\n",
    "            arr.rio.to_raster(out_file)\n",
    "            \n",
    "            #let's remove the redundant file\n",
    "            if os.path.exists(tiff_name):\n",
    "                os.remove(tiff_name)\n",
    "\n",
    "        #snow_melt_base\n",
    "        elif 'us_ssmv11044bS' in in_file:\n",
    "            tiff_name = 'us_ssmv11044bS_' + 'snow_melt_base_' + path.split(dir_path)[-1] + '.tif'\n",
    "            print(f\"Now converting {in_file}\")\n",
    "            os.system(f\"gdal_translate -of GTiff -a_srs '+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs' -a_nodata -9999 -a_ullr -124.73333333333333 52.87500000000000 -66.94166666666667 24.95000000000000 {in_file} {tiff_name}\")\n",
    "            \n",
    "            #define the name to save the final file after scaling\n",
    "            out_file = 'us_ssmv11044bS_' + 'snow_melt_base_' + path.split(dir_path)[-1] + '_m.tif'\n",
    "            #read as array and rescale\n",
    "            arr = xr.open_rasterio(tiff_name, masked = True)\n",
    "            arr = arr/100000\n",
    "            arr.rio.to_raster(out_file)\n",
    "            \n",
    "            #let's remove the redundant file\n",
    "            if os.path.exists(tiff_name):\n",
    "                os.remove(tiff_name)\n",
    "\n",
    "        #sp_avg_temp\n",
    "        elif 'us_ssmv11038wS' in in_file:\n",
    "            tiff_name = 'us_ssmv11038wS_' + 'sp_avg_temp_' + path.split(dir_path)[-1] + 'K.tif'\n",
    "            print(f\"Now converting {in_file}\")\n",
    "            os.system(f\"gdal_translate -of GTiff -a_srs '+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs' -a_nodata -9999 -a_ullr -124.73333333333333 52.87500000000000 -66.94166666666667 24.95000000000000 {in_file} {tiff_name}\")\n",
    "            \n",
    "        #sp_sublim\n",
    "        elif 'us_ssmv11050' in in_file:\n",
    "            tiff_name = 'us_ssmv11050_' + 'sp_sublim_' + path.split(dir_path)[-1] + '.tif'\n",
    "            print(f\"Now converting {in_file}\")\n",
    "            os.system(f\"gdal_translate -of GTiff -a_srs '+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs' -a_nodata -9999 -a_ullr -124.73333333333333 52.87500000000000 -66.94166666666667 24.95000000000000 {in_file} {tiff_name}\")\n",
    "            \n",
    "            #define the name to save the final file after scaling\n",
    "            out_file = 'us_ssmv11050_' + 'sp_sublim_' + path.split(dir_path)[-1] + '_m.tif'\n",
    "            #read as array and rescale\n",
    "            arr = xr.open_rasterio(tiff_name, masked = True)\n",
    "            arr = arr/100000\n",
    "            arr.rio.to_raster(out_file)\n",
    "            \n",
    "            #let's remove the redundant file\n",
    "            if os.path.exists(tiff_name):\n",
    "                os.remove(tiff_name)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('earth-analytics-python')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4a6b17c43e9812396a6a5107d266d4edbe6eaa1adb1fd72c08be9ea32f828148"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
