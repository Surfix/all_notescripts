{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as sps\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.tree import plot_tree, export_text\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 261 entries, 0 to 285\n",
      "Data columns (total 15 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Unnamed: 0             261 non-null    int64  \n",
      " 1   Location               261 non-null    object \n",
      " 2   PitID                  261 non-null    object \n",
      " 3   Density Mean (kg/m^3)  261 non-null    float64\n",
      " 4   Snow Depth (cm)        261 non-null    float64\n",
      " 5   SWE (mm)               261 non-null    float64\n",
      " 6   HH                     261 non-null    float64\n",
      " 7   HV                     261 non-null    float64\n",
      " 8   VH                     261 non-null    float64\n",
      " 9   VV                     261 non-null    float64\n",
      " 10  Temp_mean              261 non-null    float64\n",
      " 11  Ground Condition       261 non-null    object \n",
      " 12  Ground Roughness       261 non-null    object \n",
      " 13  Ground Vegetation      261 non-null    object \n",
      " 14  Canopy                 261 non-null    object \n",
      "dtypes: float64(8), int64(1), object(6)\n",
      "memory usage: 32.6+ KB\n"
     ]
    }
   ],
   "source": [
    "#read file\n",
    "uavsar_pits = pd.read_csv('/home/naheemadebisi/PhD/snow-analytics/Radar-Backscatter/pits_data/uavsar_SWE_ENV.csv')\n",
    "#drop null\n",
    "uavsar_pits.dropna(inplace = True)\n",
    "uavsar_pits.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenth of the training data is 195\n",
      "lenth of the testdata is 66\n"
     ]
    }
   ],
   "source": [
    "#train-test split\n",
    "train_df , test_df = train_test_split(uavsar_pits, test_size= 0.25, random_state= 20221104)\n",
    "print(f\"lenth of the training data is {len(train_df)}\")\n",
    "print(f\"lenth of the testdata is {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input and output data\n",
    "input_col = ['Density Mean (kg/m^3)', 'Snow Depth (cm)', 'SWE (mm)', 'Temp_mean',\n",
    "       'Ground Condition', 'Ground Roughness', 'Canopy']\n",
    "\n",
    "train_X = train_df[input_col].copy()\n",
    "test_X = test_df[input_col].copy()\n",
    "\n",
    "out_col = 'HH'\n",
    "train_Y_HH = train_df[out_col].copy()\n",
    "test_Y_HH = test_df[out_col].copy()\n",
    "\n",
    "\n",
    "#select the four numerical cols(Density, Depth, SWE, temp)\n",
    "num_cols = train_X.select_dtypes(include = np.number).columns.tolist()\n",
    "#Select the four categorical cols (Ground Condition, Ground Roughness, Ground Vegetation, Canopy)\n",
    "cat_cols = train_X.select_dtypes('object').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Density Mean (kg/m^3)</th>\n",
       "      <th>Snow Depth (cm)</th>\n",
       "      <th>SWE (mm)</th>\n",
       "      <th>Temp_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>250.743590</td>\n",
       "      <td>113.123077</td>\n",
       "      <td>299.448718</td>\n",
       "      <td>-4.112674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>72.657319</td>\n",
       "      <td>55.229304</td>\n",
       "      <td>203.338122</td>\n",
       "      <td>2.678310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>75.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>-16.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>205.250000</td>\n",
       "      <td>73.500000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>-5.506250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>268.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>-3.831250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>299.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>389.750000</td>\n",
       "      <td>-2.151429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>436.500000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>969.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Density Mean (kg/m^3)  Snow Depth (cm)    SWE (mm)   Temp_mean\n",
       "count             195.000000       195.000000  195.000000  195.000000\n",
       "mean              250.743590       113.123077  299.448718   -4.112674\n",
       "std                72.657319        55.229304  203.338122    2.678310\n",
       "min                75.000000        22.000000   55.000000  -16.250000\n",
       "25%               205.250000        73.500000  134.000000   -5.506250\n",
       "50%               268.000000       106.000000  260.000000   -3.831250\n",
       "75%               299.000000       135.000000  389.750000   -2.151429\n",
       "max               436.500000       284.000000  969.000000    0.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's see some stats for the numerical columns\n",
    "train_X[num_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ground Condition    3\n",
       "Ground Roughness    3\n",
       "Canopy              4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's check the categories in each category\n",
    "train_X[cat_cols].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "\n",
    "Todo: redo steps following jovian!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate the columnTransformer\n",
    "column_trans = ColumnTransformer((\n",
    "                ('categories', OneHotEncoder(), make_column_selector(dtype_include= object)),\n",
    "                ('scaler', StandardScaler(), make_column_selector(dtype_include= np.number))\n",
    "                      ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put transformer and predictor in a pipeline\n",
    "rf = Pipeline([\n",
    "            ('features', column_trans),\n",
    "            ('pred', RandomForestRegressor())\n",
    "            ])\n",
    "param_grid = dict(pred__n_estimators = [10, 30, 90, 270, 500, 1000], pred__max_depth = [1, 3, 9, 21, 63, 189, 250], \n",
    "                pred__max_leaf_nodes = [1, 5, 25, 75, 135, 175, 200, None],  pred__max_features = [ None, 'sqrt', 'log2'],\n",
    "                  pred__min_samples_split = [1, 2, 4, 8, 16, 32],  pred__min_samples_leaf = [1, 2, 4, 8, 16, 32], pred__bootstrap = [True, False])\n",
    "\n",
    "rf_gs = GridSearchCV(rf, param_grid= param_grid, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "98280 fits failed out of a total of 362880.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30240 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/sklearn/pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 476, in fit\n",
      "    trees = Parallel(\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/joblib/parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 117, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 189, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1342, in fit\n",
      "    super().fit(\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 265, in fit\n",
      "    check_scalar(\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 1480, in check_scalar\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split == 1, must be >= 2.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18900 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/sklearn/pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 476, in fit\n",
      "    trees = Parallel(\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/joblib/parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 117, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 189, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1342, in fit\n",
      "    super().fit(\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    check_scalar(\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 1480, in check_scalar\n",
      "    raise ValueError(\n",
      "ValueError: max_leaf_nodes == 1, must be >= 2.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30240 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/sklearn/pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 476, in fit\n",
      "    trees = Parallel(\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/joblib/parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 117, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 191, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1342, in fit\n",
      "    super().fit(\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 265, in fit\n",
      "    check_scalar(\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 1480, in check_scalar\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split == 1, must be >= 2.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18900 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/sklearn/pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 476, in fit\n",
      "    trees = Parallel(\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/joblib/parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 117, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 191, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1342, in fit\n",
      "    super().fit(\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    check_scalar(\n",
      "  File \"/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 1480, in check_scalar\n",
      "    raise ValueError(\n",
      "ValueError: max_leaf_nodes == 1, must be >= 2.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/naheemadebisi/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan ... 0.27054751 0.27601278 0.26457243]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=Pipeline(steps=[(&#x27;features&#x27;,\n",
       "                                        ColumnTransformer(transformers=((&#x27;categories&#x27;,\n",
       "                                                                         OneHotEncoder(),\n",
       "                                                                         &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f8be73565b0&gt;),\n",
       "                                                                        (&#x27;scaler&#x27;,\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f8be73566d0&gt;)))),\n",
       "                                       (&#x27;pred&#x27;, RandomForestRegressor())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;pred__bootstrap&#x27;: [True, False],\n",
       "                         &#x27;pred__max_depth&#x27;: [1, 3, 9, 21, 63, 189, 250],\n",
       "                         &#x27;pred__max_features&#x27;: [None, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;pred__max_leaf_nodes&#x27;: [1, 5, 25, 75, 135, 175, 200,\n",
       "                                                  None],\n",
       "                         &#x27;pred__min_samples_leaf&#x27;: [1, 2, 4, 8, 16, 32],\n",
       "                         &#x27;pred__min_samples_split&#x27;: [1, 2, 4, 8, 16, 32],\n",
       "                         &#x27;pred__n_estimators&#x27;: [10, 30, 90, 270, 500, 1000]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=Pipeline(steps=[(&#x27;features&#x27;,\n",
       "                                        ColumnTransformer(transformers=((&#x27;categories&#x27;,\n",
       "                                                                         OneHotEncoder(),\n",
       "                                                                         &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f8be73565b0&gt;),\n",
       "                                                                        (&#x27;scaler&#x27;,\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f8be73566d0&gt;)))),\n",
       "                                       (&#x27;pred&#x27;, RandomForestRegressor())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;pred__bootstrap&#x27;: [True, False],\n",
       "                         &#x27;pred__max_depth&#x27;: [1, 3, 9, 21, 63, 189, 250],\n",
       "                         &#x27;pred__max_features&#x27;: [None, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;pred__max_leaf_nodes&#x27;: [1, 5, 25, 75, 135, 175, 200,\n",
       "                                                  None],\n",
       "                         &#x27;pred__min_samples_leaf&#x27;: [1, 2, 4, 8, 16, 32],\n",
       "                         &#x27;pred__min_samples_split&#x27;: [1, 2, 4, 8, 16, 32],\n",
       "                         &#x27;pred__n_estimators&#x27;: [10, 30, 90, 270, 500, 1000]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;features&#x27;,\n",
       "                 ColumnTransformer(transformers=((&#x27;categories&#x27;, OneHotEncoder(),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f8be73565b0&gt;),\n",
       "                                                 (&#x27;scaler&#x27;, StandardScaler(),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f8be73566d0&gt;)))),\n",
       "                (&#x27;pred&#x27;, RandomForestRegressor())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">features: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=((&#x27;categories&#x27;, OneHotEncoder(),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f8be73565b0&gt;),\n",
       "                                (&#x27;scaler&#x27;, StandardScaler(),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f8be73566d0&gt;)))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categories</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f8be73565b0&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">scaler</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f8be73566d0&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('features',\n",
       "                                        ColumnTransformer(transformers=(('categories',\n",
       "                                                                         OneHotEncoder(),\n",
       "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x7f8be73565b0>),\n",
       "                                                                        ('scaler',\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x7f8be73566d0>)))),\n",
       "                                       ('pred', RandomForestRegressor())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'pred__bootstrap': [True, False],\n",
       "                         'pred__max_depth': [1, 3, 9, 21, 63, 189, 250],\n",
       "                         'pred__max_features': [None, 'sqrt', 'log2'],\n",
       "                         'pred__max_leaf_nodes': [1, 5, 25, 75, 135, 175, 200,\n",
       "                                                  None],\n",
       "                         'pred__min_samples_leaf': [1, 2, 4, 8, 16, 32],\n",
       "                         'pred__min_samples_split': [1, 2, 4, 8, 16, 32],\n",
       "                         'pred__n_estimators': [10, 30, 90, 270, 500, 1000]})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_gs.fit(train_X, train_Y_HH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train mse: 0.007753746195324136\n",
      "Train r_square: 0.37575065325496515\n",
      "Test mse: 0.00997885213795148\n",
      "Test r_square: 0.35819428270943354\n"
     ]
    }
   ],
   "source": [
    "#predict train\n",
    "predictions_train = rf_gs.best_estimator_.predict(train_X)\n",
    "#predict test\n",
    "predictions_test = rf_gs.best_estimator_.predict(test_X)\n",
    "\n",
    "#compute loss train\n",
    "mse_loss = mse(train_Y_HH, predictions_train)\n",
    "rsquare = r2_score(train_Y_HH, predictions_train) \n",
    "print(f'Train mse: {mse_loss}')\n",
    "print(f'Train r_square: {rsquare}')\n",
    "\n",
    "#compute loss test\n",
    "mse_loss = mse(test_Y_HH, predictions_test)\n",
    "rsquare = r2_score(test_Y_HH, predictions_test) \n",
    "print(f'Test mse: {mse_loss}')\n",
    "print(f'Test r_square: {rsquare}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12933889, 0.27202738, 0.27202738, 0.12933889, 0.27202738,\n",
       "       0.12933889, 0.27202738, 0.27202738, 0.27202738, 0.12933889,\n",
       "       0.12933889, 0.27202738, 0.12933889, 0.27202738, 0.12933889,\n",
       "       0.27202738, 0.12933889, 0.27202738, 0.27202738, 0.27202738,\n",
       "       0.27202738, 0.12933889, 0.12933889, 0.27202738, 0.27202738,\n",
       "       0.12933889, 0.12933889, 0.27202738, 0.27202738, 0.12933889,\n",
       "       0.27202738, 0.27202738, 0.12933889, 0.12933889, 0.12933889,\n",
       "       0.27202738, 0.12933889, 0.27202738, 0.27202738, 0.12933889,\n",
       "       0.12933889, 0.12933889, 0.12933889, 0.27202738, 0.27202738,\n",
       "       0.27202738, 0.27202738, 0.27202738, 0.12933889, 0.12933889,\n",
       "       0.27202738, 0.27202738, 0.12933889, 0.27202738, 0.27202738,\n",
       "       0.27202738, 0.27202738, 0.27202738, 0.12933889, 0.12933889,\n",
       "       0.12933889, 0.12933889, 0.27202738, 0.27202738, 0.27202738,\n",
       "       0.27202738])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance(fitted_model):\n",
    "    #feature importance\n",
    "    importance_df = pd.DataFrame({\n",
    "    'feature': uavsar_pits[input_col].columns,\n",
    "    'importance': fitted_model.named_steps[\"pred\"].feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "\n",
    "    plt.title('Feature Importance')\n",
    "    sns.barplot(data=importance_df.head(10), x='importance', y='feature');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_gs.best_estimator_.named_steps[\"pred\"].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_161295/2782835847.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeature_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_gs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_161295/1549350561.py\u001b[0m in \u001b[0;36mfeature_importance\u001b[0;34m(fitted_model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfeature_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitted_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#feature importance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     importance_df = pd.DataFrame({\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;34m'feature'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muavsar_pits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'importance'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfitted_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pred\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;31m# TODO: can we get rid of the dt64tz special case above?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m     return arrays_to_mgr(\n\u001b[0m\u001b[1;32m    465\u001b[0m         \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     )\n",
      "\u001b[0;32m~/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All arrays must be of the same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "feature_importance(rf_gs.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('earth-analytics-python')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4a6b17c43e9812396a6a5107d266d4edbe6eaa1adb1fd72c08be9ea32f828148"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
